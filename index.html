<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="This is a project page.">
  <meta name="keywords" content="Sign Langauge, MLLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SignGPT</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>


<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">SignGPT: Taming LLM for 
            Sign Language Translation, Generation and Conversation </h1>
          <h2 class="title is-4 publication-title">This page is under construction ... ðŸ”¨</h2>

          <div class="column has-text-centered">
            <div class="publication-links">
              

              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://signgpt26.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->

              <!-- Dataset Link.  -->
              

              <!-- <span class="link-block">
                <a href="https://signgpt26.github.io/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data is coming</span>
                </a>
                <p>
                  The complete code for training and testing, along with the dataset, will be publicly available. 
                </p> -->

           
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models (LLMs) have demonstrated impressive multilingual capabilities, 
            yet they largely overlook sign languagesâ€”a primary means of communication 
            for the deaf and hard-of-hearing communities. 
          </p>
          <p>
            To address this, we consider sign language a unique language distinct from general human motion and leverage the powerful contextual 
            modeling capabilities of LLM to construct SignGPT, a unified framework that first enables LLM to support a wide range of sign language 
            tasks, including Sign Language Translation, Generation, and  Conversation.
          </p>
          <p>
            First, we propose a Semantic Aware Sign Language Tokenizer, which efficiently encodes continuous sign language motion sequences into 
            semantically consistency latent space. 
            Next, we propose a Sign-Aware Language Model that incorporates a motion projection layer, 
            enabling the LLM to perceive fine-grained motion details.
            Third, we design a pre-training and instruction-tuning strategy, enabling SignGPT to handle sign language translation and generation based 
            on  various instructions. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>